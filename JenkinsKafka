pipeline {
    agent any
    parameters {
        string(name: 'ssh_usr', description: '# ssh user in slave machines', defaultValue : "root")        
        string(name: 'ssh_key', description: '''# Master server ssh_key
        '''  , defaultValue : "/root/.ssh/id_rsa")
        choice (choices: ['local', 'download'], name: 'packageOptions')
        booleanParam(name: 'credentials', description: 'insert only if downloadin need user and pass' , defaultValue : false)
        string(name: 'download_usr', description: '', defaultValue : "fabric_pipeline")        
        string(name: 'download_pass', description: '', defaultValue : "Q1w2e3r4t5")        
        string(name: 'packages_location', description: ' ' , defaultValue : "/home/")
//         choice (choices: ['y', 'n'], description: '''# kafka message broker y/n
// ''', name: 'KAFKA_MESSAGES_BROKER')        
        string(name: 'BOOTSTRAP_SERVERS', description: '''# in case of using existing kafka cluster please provide the BOOTSTRAP_SERVERS
# otherwise leave it blank
# ex :
#     BOOTSTRAP_SERVERS=10.21.3.36:9093,10.21.3.14:9093

#### kafka ####''')
        string(name: 'kafka_usr', description: ' ' , defaultValue : "kafka")
        string(name: 'kafka_path', description: ' ' , defaultValue : "/home/kafka")
        choice (choices: ['1', '2', '3'], name: 'kafka_RF')
        string(name: 'kafka_IP', description: ' ' , defaultValue : "10.21.3.36,10.21.3.14")
        string(name: 'kafka_download_link', description: 'insert download link only if you dont have the package localy ' , defaultValue : "http://")
        string(name: 'kafka_package', description: '' , defaultValue : "k2view_Confluent_5.3.0_Package_01.tar.gz")
        

    }
    options {
        disableConcurrentBuilds()
    }
    stages {
        stage('prepare config.ini'){
            steps{
                println("inserting configuration")
                script {
                    sh(script : "echo '''############## config.ini ##############\n\n\n############## general ##############\n\n# ssh user in slave machines''' > config.ini", returnStdout: true)
                    sh(script : "echo 'ssh_usr=$params.ssh_usr' >> config.ini", returnStdout: true)
                    // sh(script : "echo '\n# kafka message broker y/n' >> config.ini", returnStdout: true)
                    // sh(script : "echo 'KAFKA_MESSAGES_BROKER=$params.KAFKA_MESSAGES_BROKER' >> config.ini", returnStdout: true)
                    sh(script : "echo '''\n# in case of using existing kafka cluster please provide the BOOTSTRAP_SERVERS\n# otherwise leave it blank\n\n# ex :\n#     BOOTSTRAP_SERVERS=172.31.25.86:9093,172.31.26.104:9093,172.31.40.112:9093''' >> config.ini", returnStdout: true)
                    if ("$params.BOOTSTRAP_SERVERS"?.trim()) {
                        sh(script : "echo 'BOOTSTRAP_SERVERS=$params.BOOTSTRAP_SERVERS' >> config.ini", returnStdout: true)
                    }else {
                        sh(script : "echo '#BOOTSTRAP_SERVERS=' >> config.ini", returnStdout: true)
                    }
                    
                    
                    sh(script : "echo '# Master server ssh_key' >> config.ini", returnStdout: true)
                    sh(script : "echo 'ssh_key=$params.ssh_key' >> config.ini", returnStdout: true)
                    sh(script : "echo 'packages_location=$params.packages_location' >> config.ini", returnStdout: true)

                    sh(script : "echo '\n############## kafka ##############\n' >> config.ini", returnStdout: true)
                    sh(script : "echo 'kafka_usr=$params.kafka_usr' >> config.ini", returnStdout: true)
                    sh(script : "echo 'kafka_RF=$params.kafka_RF' >> config.ini", returnStdout: true)
                    sh(script : "echo 'kafka_IP=$params.kafka_IP' >> config.ini", returnStdout: true)
                    sh(script : "echo 'kafka_package=$params.kafka_package' >> config.ini", returnStdout: true)
                    sh(script : "echo 'kafka_path=$params.kafka_path' >> config.ini", returnStdout: true)
                    sh(script : "chmod +x *.sh", returnStdout: true)
                }
            }
        }
        stage('download packages'){
            when {
                    environment name: 'packageOptions', value: 'download'
                }
            steps{
                script {
                    if("$params.credentials" == "true"){
                        sh(script : "curl -u $params.download_usr:$params.download_pass -o $params.packages_location$params.kafka_package $params.kafka_download_link", returnStdout: true)
                    }else{
                        sh(script : "curl $params.kafka_download_link -o $params.packages_location$params.kafka_package", returnStdout: true)
                    }
                }
            }
        }
        stage('install kafka'){
            // when{
            //      expression { return params.install_kafka }
            // }
            steps{
                script {
                    println "################"
                    println "installing kafka on $params.kafka_IP"
                    println "################"
                    sh(script : "./kafka.sh", returnStdout: true)
                    println "################"
                    println "checking if kafka brokers UP"
                    println "################"
                    
                    def list = kafka_IP.trim().split(',')[0]
                    println("testing on node : "  + list)
                    cmd="kafka_check_$list'.sh'"
                    sh "scp -i $params.ssh_key $cmd $params.ssh_usr@$list:/$kafka_path"
                    cmd="$kafka_path/kafka_check_$list'.sh'"
                    sh "ssh -i $params.ssh_key $ssh_usr@$list $cmd"
                }
            }
        }
    }
}